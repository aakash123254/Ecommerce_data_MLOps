import os
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import joblib


# ================================================
# ğŸ“ PATHS
# ================================================
RAW_DATA_PATH = "data/raw/raw_data.xlsx"
PROCESSED_DATA_PATH = "data/processed/processed_data.csv"
FEATURE_DATA_PATH = "data/features/features.csv"
MODEL_PATH = "artifacts/model/model.pkl"
METRIC_PATH = "artifacts/metrics/metrics.txt"


# ================================================
# ğŸ§¹ STEP 1 â€” LOAD + PREPROCESS RAW DATA
# ================================================
def load_raw_data():
    print("ğŸ“¥ Loading raw data...")

    try:
        df = pd.read_excel(RAW_DATA_PATH)
        print(f"âœ… Raw data loaded. Shape: {df.shape}")
        return df
    except Exception as e:
        print(f"âŒ Failed to load raw data: {e}")
        return None


def preprocess_data(df):
    print("ğŸ§¹ Cleaning data...")

    # Remove missing InvoiceNo or CustomerID
    df = df.dropna(subset=["InvoiceNo", "CustomerID"])

    # Remove negative quantities
    df = df[df["Quantity"] > 0]

    # Remove negative prices
    df = df[df["UnitPrice"] > 0]

    # Add Sales Column
    df["Sales"] = df["Quantity"] * df["UnitPrice"]

    print(f"âœ… Preprocessing complete. Shape: {df.shape}")
    return df


def save_processed(df):
    os.makedirs(os.path.dirname(PROCESSED_DATA_PATH), exist_ok=True)
    df.to_csv(PROCESSED_DATA_PATH, index=False)
    print(f"ğŸ’¾ Processed data saved â†’ {PROCESSED_DATA_PATH}")


# ================================================
# ğŸ§© STEP 2 â€” FEATURE ENGINEERING
# ================================================
def create_features(df):
    print("ğŸ§© Creating features...")

    # Fix InvoiceDate conversion
    if not pd.api.types.is_datetime64_any_dtype(df["InvoiceDate"]):
        df["InvoiceDate"] = pd.to_datetime(df["InvoiceDate"], errors="coerce")

    # Date features
    df["InvoiceYear"] = df["InvoiceDate"].dt.year
    df["InvoiceMonth"] = df["InvoiceDate"].dt.month
    df["InvoiceDay"] = df["InvoiceDate"].dt.day
    df["InvoiceHour"] = df["InvoiceDate"].dt.hour
    df["InvoiceDayOfWeek"] = df["InvoiceDate"].dt.dayofweek

    # One-hot encode Country
    df = pd.get_dummies(df, columns=["Country"], prefix="Country", drop_first=True)

    # Drop non-numeric & unnecessary columns
    drop_cols = ["InvoiceNo", "Description", "InvoiceDate", "StockCode"]
    df.drop(columns=[c for c in drop_cols if c in df.columns], inplace=True)

    print(f"âœ… Features created. Shape: {df.shape}")
    return df



def save_features(df):
    os.makedirs(os.path.dirname(FEATURE_DATA_PATH), exist_ok=True)
    df.to_csv(FEATURE_DATA_PATH, index=False)
    print(f"ğŸ’¾ Feature data saved â†’ {FEATURE_DATA_PATH}")


# ================================================
# ğŸ¤– STEP 3 â€” MODEL TRAINING
# ================================================
def train_model(X_train, y_train):
    print("ğŸ¤– Training model...")

    model = RandomForestRegressor(
        n_estimators=200,
        max_depth=12,
        random_state=42,
        n_jobs=-1
    )

    model.fit(X_train, y_train)

    print("âœ… Training complete.")
    return model


def save_model(model):
    os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)
    joblib.dump(model, MODEL_PATH)
    print(f"ğŸ’¾ Model saved â†’ {MODEL_PATH}")


# ================================================
# ğŸ“Š STEP 4 â€” MODEL EVALUATION
# ================================================
def evaluate_model(model, X_test, y_test):
    print("ğŸ“Š Evaluating model...")

    preds = model.predict(X_test)

    mae = mean_absolute_error(y_test, preds)
    mse = mean_squared_error(y_test, preds)
    rmse = mse ** 0.5
    r2 = r2_score(y_test, preds)

    print(f"ğŸ“Œ MAE : {mae:.4f}")
    print(f"ğŸ“Œ MSE : {mse:.4f}")
    print(f"ğŸ“Œ RMSE: {rmse:.4f}")
    print(f"ğŸ“Œ R2  : {r2:.4f}")

    # Save metrics
    os.makedirs(os.path.dirname(METRIC_PATH), exist_ok=True)
    with open(METRIC_PATH, "w") as f:
        f.write(f"MAE: {mae}\nMSE: {mse}\nRMSE: {rmse}\nR2: {r2}\n")

    print(f"ğŸ’¾ Metrics saved â†’ {METRIC_PATH}")

    return mae, mse, rmse, r2


# ================================================
# ğŸš€ MAIN EXECUTION PIPELINE
# ================================================
def main():
    # Step 1 â€” Raw â†’ Processed
    df_raw = load_raw_data()
    if df_raw is None:
        print("âŒ Pipeline stopped. Raw data not found.")
        return

    df_processed = preprocess_data(df_raw)
    save_processed(df_processed)

    # Step 2 â€” Processed â†’ Features
    df_features = create_features(df_processed)
    save_features(df_features)

    # Step 3 â€” Train/Test Split
    print("âœ‚ Splitting dataset...")
    X = df_features.drop("Sales", axis=1)
    y = df_features["Sales"]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    print(f"ğŸ“Š Train: {X_train.shape}, Test: {X_test.shape}")

    # Train model
    model = train_model(X_train, y_train)
    save_model(model)

    # Step 4 â€” Evaluate
    evaluate_model(model, X_test, y_test)

    print("\nğŸ‰ Pipeline execution completed successfully!")


if __name__ == "__main__":
    main()
